# get the trinton server files
Bootstrap: docker
From: nvcr.io/nvidia/tritonserver:20.06-v1-py3-clientsdk
Stage: build

# PyTorch container
Bootstrap: docker
From: nvcr.io/nvidia/pytorch:20.06-py3
Stage: final

# copy files from trinton/workspace/install/ to PyTorch/workspace/install/
%files from build
    /workspace/install /workspace/

%post
    apt-get update && apt-get install -y pbzip2 pv bzip2 cabextract htop
    cd /workspace
    git clone https://github.com/attardi/wikiextractor.git && cd wikiextractor && git checkout 6408a430fc504a38b04d37ce5e7fc740191dee16 && cd ..
    git clone https://github.com/soskek/bookcorpus.git

    # Install trt python api
    apt-get install -y libb64-0d
    pip install /workspace/install/python/tensorrtserver*.whl
    mkdir /workspace/bert/
    cd /workspace/bert/

    pip install --no-cache-dir \
    tqdm boto3 requests six ipdb h5py nltk progressbar onnxruntime \
    git+https://github.com/NVIDIA/dllogger wget

    apt-get install -y iputils-ping

%environment
export BERT_PREP_WORKING_DIR=/workspace/bert/data
export LD_LIBRARY_PATH=/workspace/install/lib:${LD_LIBRARY_PATH}
%runscript
cd /workspace/bert/
exec /bin/bash "$@"
%startscript
cd /workspace/bert/
exec /bin/bash "$@"